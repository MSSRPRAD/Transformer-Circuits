{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6AXLM2oL_hAb"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X8PCKoDJLJPd",
    "outputId": "42fcaf95-cbfa-4cc3-b42f-20e0de5a1ae2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x75789efc9bb0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8-RYsi34g7bT"
   },
   "source": [
    "### Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "fUlG8BZ-_VRn"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            d_model - Hidden dimensionality of the input.\n",
    "            max_len - Maximum length of a sequence to expect.\n",
    "        \"\"\"\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # Create a long tensor with positions from 0 to max_len - 1\n",
    "        pos = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "\n",
    "        # Create a tensor with indices divided by 10000^(2i/d_model)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "\n",
    "        # Compute the positional encodings\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pe[:, 0::2] = torch.sin(pos * div_term)\n",
    "        pe[:, 1::2] = torch.cos(pos * div_term)\n",
    "\n",
    "        # Register the positional encodings as buffer\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Apply positional encodings to input tensor x.\n",
    "        Args:\n",
    "            x: Input tensor of shape (batch_size, seq_len, d_model).\n",
    "        Returns:\n",
    "            Tensor: Output tensor after adding positional encodings.\n",
    "        \"\"\"\n",
    "        pe = self.pe[:x.size(1)]  # Take the relevant positional encodings\n",
    "        x = x + pe.unsqueeze(0)  # Add the positional encodings to the input tensor\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AFbB-dc1cZfE",
    "outputId": "0bf2d51c-8c2b-4daf-85ee-066347efa04f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensor shape: torch.Size([2, 500, 512])\n",
      "Encoded tensor shape: torch.Size([2, 500, 512])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "seq_len = 500\n",
    "d_model = 512\n",
    "x = torch.randn(batch_size, seq_len, d_model)\n",
    "\n",
    "max_len = 10000\n",
    "pos_encoder = PositionalEncoding(d_model, max_len)\n",
    "\n",
    "x_encoded = pos_encoder(x)\n",
    "\n",
    "print(\"Input tensor shape:\", x.shape)\n",
    "print(\"Encoded tensor shape:\", x_encoded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XTvbW_Jvg-oK"
   },
   "source": [
    "### Attention Matrix and Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "l-7T80yKDI4A"
   },
   "outputs": [],
   "source": [
    "def scaled_dot_product(q, k, v, mask=None):\n",
    "    d_k = q.size()[-1]\n",
    "    attn_logits = torch.matmul(q, k.transpose(-2, -1))\n",
    "    attn_logits = attn_logits / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        attn_logits = attn_logits.masked_fill(mask, float('-inf'))\n",
    "    attention = F.softmax(attn_logits, dim=-1)\n",
    "    values = torch.matmul(attention, v)\n",
    "    return values, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "esKtbmWUBw_y",
    "outputId": "2f621656-2378-434c-af8c-2cef00c1eb26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q\n",
      " torch.Size([50, 25, 10, 5])\n",
      "K\n",
      " torch.Size([50, 25, 10, 5])\n",
      "V\n",
      " torch.Size([50, 25, 10, 5])\n",
      "Values\n",
      " torch.Size([50, 25, 10, 5])\n",
      "Attention\n",
      " torch.Size([50, 25, 10, 10])\n"
     ]
    }
   ],
   "source": [
    "seq_len, d_k = 10, 5\n",
    "q = torch.randn(50, 25, seq_len, d_k)\n",
    "k = torch.randn(50, 25, seq_len, d_k)\n",
    "v = torch.randn(50, 25, seq_len, d_k)\n",
    "values, attention = scaled_dot_product(q, k, v)\n",
    "print(\"Q\\n\", q.shape)\n",
    "print(\"K\\n\", k.shape)\n",
    "print(\"V\\n\", v.shape)\n",
    "print(\"Values\\n\", values.shape)\n",
    "print(\"Attention\\n\", attention.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qHKSutk9hF_v"
   },
   "source": [
    "### MultiHead Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "vWNESJyCbl05"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, head_dim, num_heads):\n",
    "        super().__init__()\n",
    "        self.head_dim = head_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # Get Query, Key and Value matrices for each of the attention heads\n",
    "        self.Qs = nn.Parameter(torch.randn(d_model, num_heads * head_dim))\n",
    "        self.Ks = nn.Parameter(torch.randn(d_model, num_heads * head_dim))\n",
    "        self.Vs = nn.Parameter(torch.randn(d_model, num_heads * head_dim))\n",
    "\n",
    "        # Project the values back to d_model\n",
    "        self.o_proj = nn.Parameter(torch.randn(head_dim, d_model))\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_length, _ = x.size()\n",
    "\n",
    "        # print(\"Qs shape:\", self.Qs.shape)\n",
    "        # print(\"Ks shape:\", self.Ks.shape)\n",
    "        # print(\"Vs shape:\", self.Vs.shape)\n",
    "\n",
    "        # Get the Qs, Ks and Vs for each of the attention heads\n",
    "        qs = torch.matmul(x, self.Qs).view(batch_size, seq_length, self.num_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        ks = torch.matmul(x, self.Ks).view(batch_size, seq_length, self.num_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        vs = torch.matmul(x, self.Vs).view(batch_size, seq_length, self.num_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "\n",
    "        # Mask\n",
    "        mask = torch.triu(torch.ones(seq_length, seq_length, device=x.device), diagonal=1).bool()\n",
    "        \n",
    "        # print(\"Query tensor shape:\", qs.shape)\n",
    "        # print(\"Key tensor shape:\", ks.shape)\n",
    "        # print(\"Value tensor shape:\", vs.shape)\n",
    "\n",
    "        # Get the Attention Matrices for each of the attention heads\n",
    "        values, attentions = scaled_dot_product(qs, ks, vs, mask)\n",
    "\n",
    "        # print(\"Attentions:\", attentions.shape)\n",
    "        # print(\"Values:\", values.shape)\n",
    "\n",
    "\n",
    "        # Get the outputs by projecting back to the output dim\n",
    "        outputs = torch.matmul(values, self.o_proj).permute(0, 2, 1, 3)\n",
    "        outputs = torch.sum(outputs, dim=2)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g_d-N6y8oojk",
    "outputId": "898728a5-ce52-4f29-8c74-700dd37a6ada"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensor shape: torch.Size([16, 1000, 1024])\n",
      "Output tensor shape: torch.Size([16, 1000, 1024])\n"
     ]
    }
   ],
   "source": [
    "# Create a sample input tensor\n",
    "batch_size = 16\n",
    "seq_len = 1000\n",
    "d_model = 1024\n",
    "embed_dim = 64\n",
    "num_heads = 4\n",
    "x = torch.randn(batch_size, seq_len, d_model)\n",
    "\n",
    "# Create the MultiheadAttention module\n",
    "attn = MultiHeadAttention(d_model, embed_dim, num_heads)\n",
    "\n",
    "# Apply the multi-head attention to the input tensor\n",
    "output = attn(x)\n",
    "\n",
    "print(\"Input tensor shape:\", x.shape)\n",
    "print(\"Output tensor shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bm4iw2eFHr3l"
   },
   "source": [
    "### N Layer Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "uW3G1LdRFlUd"
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "class TransformerNLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, num_layers, d_model, embed_dim, num_heads, vocab_size):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.mha_layers = nn.ModuleList([MultiHeadAttention(d_model, embed_dim, num_heads) for _ in range(num_layers)])\n",
    "        self.positional_encoder = PositionalEncoding(d_model, 10000)\n",
    "        self.embed = nn.Parameter(torch.randn(vocab_size, d_model))\n",
    "        self.unembed = nn.Parameter(torch.randn(d_model, vocab_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        embeddings = torch.matmul(x, self.embed)\n",
    "        stream = self.positional_encoder(embeddings)\n",
    "        \n",
    "        for layer in self.mha_layers:\n",
    "            outputs = layer(stream.clone())  # Apply each MHA layer\n",
    "            stream += outputs  # Add residual connection\n",
    "            \n",
    "        logits = torch.matmul(stream, self.unembed)\n",
    "        probabilities = F.softmax(logits, dim=-1)\n",
    "\n",
    "        return probabilities\n",
    "\n",
    "    def parameters(self, recurse=True):\n",
    "        # Override parameters method to include parameters of mha_layers, embed, and unembed\n",
    "        params = super().parameters()\n",
    "        for layer in self.mha_layers:\n",
    "            params = chain(params, layer.parameters(recurse=recurse))\n",
    "        params = chain(params, [self.embed, self.unembed])\n",
    "        return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "71eEnFlQHdxP",
    "outputId": "d92cd2cc-a28e-4499-b241-bb7a1f3e6b5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input logits shape: torch.Size([16, 32, 500])\n",
      "Output logits shape: torch.Size([16, 32, 500])\n"
     ]
    }
   ],
   "source": [
    "d_model = 512\n",
    "embed_dim = 64\n",
    "num_heads = 4\n",
    "vocab_size = 500\n",
    "seq_length = 32\n",
    "batch_size = 16\n",
    "\n",
    "transformer_layer = TransformerNLayer(3, d_model, embed_dim, num_heads, vocab_size)\n",
    "\n",
    "x = torch.randn(batch_size, seq_length, vocab_size)\n",
    "\n",
    "output_logits = transformer_layer(x)\n",
    "print(\"Input logits shape:\", x.shape)\n",
    "print(\"Output logits shape:\", output_logits.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RRY9Vf-zKeML"
   },
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "mYSY4UdYZYPi"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# List of URLs\n",
    "# urls = [\n",
    "#     \"https://raw.githubusercontent.com/amephraim/nlp/master/texts/J.%20K.%20Rowling%20-%20Harry%20Potter%201%20-%20Sorcerer's%20Stone.txt\",\n",
    "#     \"https://raw.githubusercontent.com/amephraim/nlp/master/texts/J.%20K.%20Rowling%20-%20Harry%20Potter%202%20-%20The%20Chamber%20Of%20Secrets.txt\",\n",
    "#     \"https://raw.githubusercontent.com/amephraim/nlp/master/texts/J.%20K.%20Rowling%20-%20Harry%20Potter%203%20-%20Prisoner%20of%20Azkaban.txt\",\n",
    "#     \"https://raw.githubusercontent.com/amephraim/nlp/master/texts/J.%20K.%20Rowling%20-%20Harry%20Potter%204%20-%20The%20Goblet%20of%20Fire.txt\"\n",
    "# ]\n",
    "\n",
    "urls = [\n",
    "    \"https://raw.githubusercontent.com/amephraim/nlp/master/texts/J.%20K.%20Rowling%20-%20Harry%20Potter%201%20-%20Sorcerer's%20Stone.txt\"\n",
    "]\n",
    "\n",
    "# Initialize an empty string to store the concatenated content\n",
    "concatenated_content = \"\"\n",
    "\n",
    "# Loop through each URL\n",
    "for url in urls:\n",
    "    # Fetch the content from the URL\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Append the content to the concatenated string\n",
    "        concatenated_content += response.text\n",
    "    else:\n",
    "        # Print an error message if the request failed\n",
    "        print(f\"Failed to fetch content from URL: {url}\")\n",
    "\n",
    "# Now the variable concatenated_content contains the concatenated content of all URLs as a single string\n",
    "HARRY_POTTER = concatenated_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MCrDnBxU9Ye8"
   },
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YXeK7Ex21eQX",
    "outputId": "7c77e041-9467-481a-fa32-61d4914e63ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pytorch-nlp in /home/mpradyumna/.local/lib/python3.10/site-packages (0.5.0)\n",
      "Requirement already satisfied: nltk in /home/mpradyumna/.local/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: numpy in /home/mpradyumna/.local/lib/python3.10/site-packages (from pytorch-nlp) (1.26.4)\n",
      "Requirement already satisfied: tqdm in /home/mpradyumna/.local/lib/python3.10/site-packages (from pytorch-nlp) (4.66.2)\n",
      "Requirement already satisfied: click in /usr/lib/python3/dist-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/mpradyumna/.local/lib/python3.10/site-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: joblib in /home/mpradyumna/.local/lib/python3.10/site-packages (from nltk) (1.3.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-nlp nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "-VYEoqWa6teU"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/mpradyumna/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from torchnlp.encoders.text import TreebankEncoder\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "HyQ6C3NVW_1h"
   },
   "outputs": [],
   "source": [
    "data = HARRY_POTTER.lower().split(\"\\n\")\n",
    "data = [w.split() for w in data]\n",
    "data = [w for w in data if w]\n",
    "new_data = []\n",
    "for item in data:\n",
    "    for it in item:\n",
    "        new_data.append(it)\n",
    "# data = [w for w in data if not w.lower() in stop_words]\n",
    "data = new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded: [7, 5, 4, 4, 8, 0, 10, 8, 3, 4, 6, 0, 1, 2, 9, 7, 8, 11]\n",
      "Decoded: ['hello', 'world', 'python']\n"
     ]
    }
   ],
   "source": [
    "class CharacterTokenizer:\n",
    "    def __init__(self):\n",
    "        self.char_to_index = {}\n",
    "        self.index_to_char = {}\n",
    "\n",
    "    def fit(self, words):\n",
    "        chars = set(''.join(words))\n",
    "        index = 1  # Start index from 1, as 0 will always represent space\n",
    "        for char in chars:\n",
    "            if char != ' ':  # Skip space\n",
    "                self.char_to_index[char] = index\n",
    "                self.index_to_char[index] = char\n",
    "                index += 1\n",
    "\n",
    "    def encode(self, words):\n",
    "        encoded_tokens = []\n",
    "        for word in words:\n",
    "            encoded_word = [self.char_to_index.get(char, 0) for char in word]\n",
    "            encoded_tokens.extend(encoded_word + [0])  # Concatenate with 0\n",
    "        # Remove the trailing 0\n",
    "        if encoded_tokens and encoded_tokens[-1] == 0:\n",
    "            encoded_tokens.pop()\n",
    "        return encoded_tokens\n",
    "\n",
    "    def decode(self, encoded_tokens):\n",
    "        decoded_words = []\n",
    "        current_word = ''\n",
    "        for token in encoded_tokens:\n",
    "            if token == 0:\n",
    "                decoded_words.append(current_word)\n",
    "                current_word = ''\n",
    "            else:\n",
    "                current_word += self.index_to_char.get(token, '')\n",
    "        if current_word:\n",
    "            decoded_words.append(current_word)\n",
    "        return decoded_words\n",
    "\n",
    "# Example usage:\n",
    "words = [\"hello\", \"world\", \"python\"]\n",
    "tokenizer = CharacterTokenizer()\n",
    "tokenizer.fit(words)\n",
    "\n",
    "encoded_tokens = tokenizer.encode(words)\n",
    "print(\"Encoded:\", encoded_tokens)\n",
    "\n",
    "decoded_words = tokenizer.decode(encoded_tokens)\n",
    "print(\"Decoded:\", decoded_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = CharacterTokenizer()\n",
    "encoder.fit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uURvtJiS9aAP"
   },
   "source": [
    "### Train the Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "LaUFil1R-G4e"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1_g92VwNAsKM",
    "outputId": "d989e513-ea12-4112-ff76-3f69a8061bb2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([879483, 51])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encoder = TreebankEncoder(data)\n",
    "tokens = encoder.encode(HARRY_POTTER)\n",
    "tokens = torch.Tensor(tokens).to(torch.int64)\n",
    "tokens = F.one_hot(tokens).float()\n",
    "tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 512\n",
    "embed_dim = 64\n",
    "num_heads = 12\n",
    "vocab_size = tokens.shape[1]\n",
    "seq_length = 300\n",
    "batch_size = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "pyvkl55AFStS"
   },
   "outputs": [],
   "source": [
    "# Group tokens into batches\n",
    "num_batches = len(tokens) // (batch_size * seq_length)\n",
    "tokens = tokens[:num_batches * batch_size * seq_length]\n",
    "tokens = tokens.view(batch_size, -1, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mpradyumna/.local/lib/python3.10/site-packages/torch/_compile.py:24: UserWarning: optimizer contains a parameter group with duplicate parameters; in future, this will cause an error; see github.com/pytorch/pytorch/issues/40967 for more information\n",
      "  return torch._dynamo.disable(fn, recursive)(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "transformer_layer = TransformerNLayer(2, d_model, embed_dim, num_heads, vocab_size).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(transformer_layer.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method TransformerNLayer.parameters of TransformerNLayer(\n",
       "  (mha_layers): ModuleList(\n",
       "    (0-1): 2 x MultiHeadAttention()\n",
       "  )\n",
       "  (positional_encoder): PositionalEncoding()\n",
       ")>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_layer.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 512
    },
    "id": "165I9rd39Zjn",
    "outputId": "ca9442f5-0af9-4ab1-f77b-46735b7f5b36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Average Loss: 33.4205\n",
      "Epoch [2/100], Average Loss: 33.4205\n"
     ]
    }
   ],
   "source": [
    "foo = None\n",
    "tmp = None\n",
    "\n",
    "transformer_layer.to(device)\n",
    "for epoch in range(2):\n",
    "    total_loss = 0.0\n",
    "    for i in range(tokens.size(1) // seq_length):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        start_idx = i * seq_length\n",
    "        end_idx = (i + 1) * seq_length\n",
    "        x = tokens[:, start_idx:end_idx, :].to(device)\n",
    "        output_logits = transformer_layer(x)[:, :-1]\n",
    "\n",
    "        foo = x[:, 1:]\n",
    "        tmp = output_logits\n",
    "        \n",
    "        target = x[:, 1:]\n",
    "        # Compute the loss\n",
    "        loss = criterion(output_logits, target)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    # Print average loss for the epoch\n",
    "    print(f\"Epoch [{epoch + 1}/{100}], Average Loss: {total_loss / (tokens.size(1) // seq_length):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "Xu2hPhXiJkEF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' r i g h t ,   t h a t \\' s   w h a t       h e a r d   y e s ,   t h e i r   s o n ,     a r r y \"       r .     u r s l e y   s t o p p e d   d e a d .     e a r   f l o o d e d   h i m .     e   l o o k e d   b a c k   a t   t h e   w h i s p e r e r s   a s   i f   h e   w a n t e d   t o   s a'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(encoder.decode(torch.argmax(foo, dim=2)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'66666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(encoder.decode(torch.argmax(tmp, dim=2)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "4rgtPrPUGTlk",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "transformer_layer.to('cpu')\n",
    "idx = 10\n",
    "input_tokens = tokens[0][:idx].view(1, idx, tokens[0][:idx].shape[1]).to('cpu')\n",
    "context = input_tokens\n",
    "predicted_tokens = []\n",
    "\n",
    "for i in range(100):\n",
    "    print(i)\n",
    "    predicted_token = transformer_layer(context)[:, -1, :]\n",
    "    predicted_tokens.append(predicted_token)\n",
    "    idx += 1\n",
    "    context = tokens[0][:idx].view(1, idx, tokens[0][:idx].shape[1]).to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_tokens = torch.stack(predicted_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "XL_MxWPwIO3a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_token_ids = torch.argmax(predicted_tokens, dim=2)\n",
    "predicted_token_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 110, 51])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "91qmXTxVIeew"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = encoder.decode(predicted_token_ids.view(-1).tolist())\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "DuSEepWrKC82"
   },
   "outputs": [],
   "source": [
    "actual = encoder.decode(torch.argmax(context, dim=2)[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "Vg7z1JuUKZV3"
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "c44VKs0gKXgJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "VMFLEBTsKfwo"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"  a r r y     o t t e r   a n d   t h e     o r c e r e r ' s     t o n e                                    \""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OtgE9f7qI6MS"
   },
   "source": [
    "### Visualizing Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "FXxr_7dOPqgX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 50, 51])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tokens = tokens[0][:50].view(1, 50, tokens[0][:50].shape[1]).to('cpu')\n",
    "input_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "eUj4TiptP87F"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TransformerNLayer' object has no attribute 'mha'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(input_tokens, transformer_layer\u001b[38;5;241m.\u001b[39membed)\n\u001b[1;32m      2\u001b[0m outputs \u001b[38;5;241m=\u001b[39m transformer_layer\u001b[38;5;241m.\u001b[39mpositional_encoder(embeddings)\n\u001b[0;32m----> 3\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer_layer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmha\u001b[49m(embeddings)\n\u001b[1;32m      4\u001b[0m outputs\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1688\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1687\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1688\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TransformerNLayer' object has no attribute 'mha'"
     ]
    }
   ],
   "source": [
    "embeddings = torch.matmul(input_tokens, transformer_layer.embed)\n",
    "outputs = transformer_layer.positional_encoder(embeddings)\n",
    "outputs = transformer_layer.mha(embeddings)\n",
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S5EuruYeRTxg"
   },
   "outputs": [],
   "source": [
    "batch_size, seq_length, _ = embeddings.size()\n",
    "print(\"Qs shape:\", transformer_layer.mha.Qs.shape)\n",
    "print(\"Ks shape:\", transformer_layer.mha.Ks.shape)\n",
    "print(\"Vs shape:\", transformer_layer.mha.Vs.shape)\n",
    "\n",
    "# Get the Qs, Ks and Vs for each of the attention heads\n",
    "qs = torch.matmul(embeddings, transformer_layer.mha.Qs).view(batch_size, seq_length, transformer_layer.mha.num_heads, transformer_layer.mha.head_dim).permute(0, 2, 1, 3)\n",
    "ks = torch.matmul(embeddings, transformer_layer.mha.Ks).view(batch_size, seq_length, transformer_layer.mha.num_heads, transformer_layer.mha.head_dim).permute(0, 2, 1, 3)\n",
    "vs = torch.matmul(embeddings, transformer_layer.mha.Vs).view(batch_size, seq_length, transformer_layer.mha.num_heads, transformer_layer.mha.head_dim).permute(0, 2, 1, 3)\n",
    "\n",
    "print(\"Query tensor shape:\", qs.shape)\n",
    "print(\"Key tensor shape:\", ks.shape)\n",
    "print(\"Value tensor shape:\", vs.shape)\n",
    "\n",
    "# Get the Attention Matrices for each of the attention heads\n",
    "values, attentions = scaled_dot_product(qs, ks, vs)\n",
    "print(\"Values:\", values.shape)\n",
    "print(\"Attentions:\", attentions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4QGko9fDRzxo"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gtHiy-0WWery"
   },
   "outputs": [],
   "source": [
    "input_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b8UwgfdiV1g3"
   },
   "outputs": [],
   "source": [
    "torch.argmax(input_tokens.view(input_tokens.shape[1], input_tokens.shape[2]), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xsoQugYfR3uV"
   },
   "outputs": [],
   "source": [
    "attentions = attentions.squeeze(0).cpu().detach().numpy()  # Remove batch dimension and move to CPU\n",
    "decoded_tokens = [encoder.decode([i.tolist()]) for i in torch.argmax(input_tokens.view(-1, input_tokens.shape[-1]), dim=1)]\n",
    "\n",
    "# Plot each attention matrix\n",
    "for i in range(attentions.shape[0]):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    sns.heatmap(attentions[i], cmap=\"YlGnBu\", xticklabels=decoded_tokens, yticklabels=decoded_tokens)\n",
    "    plt.title(f\"Attention Matrix {i+1}\")\n",
    "    plt.xlabel(\"Source tokens\")\n",
    "    plt.ylabel(\"Target tokens\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
